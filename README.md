# Neo TitanicML 

Новые игрушки для работы с machine learning выходят очень часто, но не все они цепляют и вызывают желание разобраться в них. Однако, вышедшая летом 2020 года [статья на Хабре](https://habr.com/ru/company/abbyy/blog/506808/ "ABBYY NeoML: как мы делали библиотеку машинного обучения и зачем она нужна") сотрудника ABBYY о выпуске библиотеки [NeoML](https://github.com/neoml-lib/neoml "NeoML") в мир свободного ПО привлекла внимание. Для своего пет-проекта уже долгое время в фоновом режиме занимаюсь поиском инструмента для кросплатформенного использования ML-моделей, поэтому интересно, на сколько успешным получилось решение ABBYY.

Для теста выбрана классическая задача бинарной классификации [TitanicML](https://www.kaggle.com/c/titanic "Titanic - Machine Learning from Disaster"). План теста следующий:
1. На фазе исследования создать решение с использованием привычных инструментов (Python, Pandas и SkLearn).
2. Перенести решение на язык C++ с использованием библиотеки NeoML.
3. Оценить решение на качество (по выбранной метрике) и на комфортность переноса (субъективные впечатления).

Вот что в итоге получилось.

## Ресёрч

Для исследования возьмём простое, без изощрённого feature-инжиниринга решение, обладающее предсказательной силой, заметно большей, чем подбрасывание монетки в вакууме. Это позволит попробовать в новой среде базовые подходы для подготовки данных и, собственно, обучение. Таким решением является простая векторизация со скалированием исходных данных и применение классификатора на основе SVM. 

В исходных данных существует проблема - для некоторых записей отсутствуют значения возраста и места посадки. Будем считать местом посадки исходную точку отплытия Титаника - Southampton. А для "лечения" столбца возраст возьмём случайное значение в окрестности одной сигмы (стандартного отклонения) от среднего значения возрастов.

С подробным описанием можно ознакомиться в jupyter-ноутбуке [research/notebook.ipynb](research/notebook.ipynb), а здесь приведу для иллюстрации следующий код:


```python
# == Подготовка данных

X_train, X_test = random_sigma_age_fillna(X_train, X_test, mean_age, sigma)

# Кодирование
sex_encoder = LabelEncoder()
X_train["Sex"] = sex_encoder.fit_transform(X_train["Sex"])
X_test["Sex"] = sex_encoder.transform(X_test["Sex"])

embarked_encode = LabelEncoder()
X_train["Embarked"] = embarked_encode.fit_transform(X_train["Embarked"])
X_test["Embarked"] = embarked_encode.transform(X_test["Embarked"])

# Скэйлинг
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# == Обучение
classifier = SVC(kernel = 'rbf')
classifier.fit(X_train, Y_train)

# == Тест
test_predict = classifier.predict(X_test)
acc = accuracy_score(Y_test, test_predict)

print("Test accuracy = {:.2f}".format(acc * 100))
# output: Test accuracy = 84.33
```
Итак, **точность** на тесте получилась **84.33**, запомним это. Также сохраним параметры подготовки данных в json-конфиг - это позволит настроить пайплайн в коде на C++.


## NeoML Реализация

Настало время С++. На этом этапе есть понимание как подготовить данные и какой алгоритм обучения использовать. Для тестовой реализации хочется использовать максимально независимый от сторонних библиотек код, поэтому нет желания тащить boost-монстров для простых задач, например, чтения csv-файлов.

### Подготовка данных
Классические алгоритмы в библиотеке NeoML на входе ожидают класс с интерфейсом `IProblem`. Воспользуемся их же реализацией - классом `CMemoryProblem`, который содержит весь датасет в памяти. Для подготовки данных имеющиеся сэмплы нужно уложить в feature-вектор и добавить в CMemoryProblem.

Но, во-первых, csv-файл с исходными данными нужно прочитать. Для этого реализован простой, робустный `CsvReader`, который позволяет читать файл построчно и разбивать прочитанную строку, согласно разделителю. Метод получения списка полей из прочитанной строки в csv-файле:
```c++
bool CsvReader::Next(vector<string>& fields_out);
```
Полученный список полей необходимо интерпретировать и представить в структурированном виде. С этой задачей справляется конвертер `PassengerInfoConverter`, который из массива строк создаёт структуру `PassengerInfo` - она содержит все данные о пассажире. При подготовке PassengerInfo случайное значение возраста получается с помощью функции из NeoML:
```c++
auto random = NeoML::CRandom();
passenger_info.age = random.UniformInt(min_age,    // mean_age - std_age
                                       max_age     // mean_age + std_age
```
Конвертер PassengerInfoConverter подготавливает из PassengerInfo feature-вектор `NeoML::CSparseFloatVector`. В качестве `LabelEncoder` используется простая обёртка над `map<string, int>`. Значения полученного вектора необходимо заскэйлить по алгоритму StandartScale, т.е. из координат вычесть среднее значение и разделить на сигму:
```
z = (x - mean) / std
```
Для иллюстрации всей процелуры подготовки датасета вот код:

```c++
CPtr<CMemoryProblem> dataset = new CMemoryProblem(features_count, kClassCount);

while (csv_reader->Next(fields)) {

    // прочитанную строку преобразовать в инфо о пассажире
    PassengerInfo info;
    bool success = converter->FromStrings(fields, info);

    // инфо о пассажире перевести в вектор
    NeoML::CSparseFloatVector vect;
    int class_id = converter->Info2Vec(info, vect);
    vect = scaler->Transform(vect);

    dataset->Add(vect, class_id);
}
```
Готово! Датасет можно сохранить в файл и дальше использовать его напрямую.

### Обучение
Чтож подготовка данных - наверно, 90% всей работы. Осталась самое простое - обучить модель. Для управления обучением и тестами реализован класс `Agent`, интерфейс которого позволяет загружать в память датасеты; загружать и сохранять обученную модель; обучать и проводить валидацию модели.

Обучение взято из туториала NeoML:
```c++
CSvm::CParams params(CSvmKernel::KT_RBF);
params.Tolerance = 0.001; // из SkLearn

CSvm svm(params);

CPtr<IModel> model = svm.Train(*train_dataset);

float train_score = Validate(model, train_dataset);
float test_score = Validate(model, test_dataset);

cout << "Train accuracy: " << train_score * 100 << "\n";
cout << "Test accuracy: " << test_score * 100 << "\n";

// Output:
// Train accuracy: 84.34
// Test accuracy: 84.59
```
Ура! **Точность** на тесте получилась **84.59**, что предельно близко к результату на Python.

## Выводы

Библиотека NeoML позволила построить законченное решение на основе классического алгоритма бинарной классификации. Реализация на C++, согласно выбранной метрики, по качеству совпадает с Python версии. Вместе с тем, использование низкоуровневого языка позволяет интегрировать модель в приложения на различных платформах. Таким образом, библиотека NeoML помогает успешно решать задачу, для которой она и создавалась.

Библиотека обладает продуманной архитектурой и понятно написанным кодом, что позволяет разобраться во внутреннем устройстве. Однако, популярность проектов в мире свободного ПО во многом зависит не только от качества исполнения, но и от качества и полноты сопутствующей документации. Конечно, разработчики проделали много работы для написания примеров использования и описания API библиотеки. Но выглядит крайне полезным создать чистую, логично построенную документацию с использованием лучших современных практик, например, на основе Sphinx (и плагинов для C++). Также было бы полезным добавление серии туториалов, что называется "from scratch": от линейной алгебры с векторами, до классических алгоритмов и различных видов нейронных сетей. Таким образом, проект сможет предоставить заметно более низкий порог входа, навигацию в API и поиск требуемых классов/интерфейсов/методов.

Интересно попробовать библотеку в работе с нейронными сетями, а так же попробовать реализовать алгоритм reinforcement learning с Deep Q-Learning, который обучается непосредственно в конечном устройстве. Кто знает, может именно NeoML поможет это осуществить ;)